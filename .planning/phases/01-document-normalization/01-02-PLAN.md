---
phase: 01-document-normalization
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified: [src/models/token.py, src/pipeline/tokenizer.py, src/pipeline/ocr_abstraction.py, tests/test_tokenizer.py]
autonomous: true

must_haves:
  truths:
    - "System can extract tokens with bounding boxes (x, y, width, height) from searchable PDFs using pdfplumber"
    - "System can extract tokens with bounding boxes from scanned PDFs using OCR"
    - "All tokens preserve spatial information (bbox) regardless of source"
    - "Token extraction maintains reading order"
    - "OCR abstraction layer allows switching engines without pipeline changes"
  artifacts:
    - path: "src/models/token.py"
      provides: "Token data model with text, bbox (x, y, width, height), page reference"
      contains: "class Token"
    - path: "src/pipeline/tokenizer.py"
      provides: "Token extraction from pdfplumber (searchable PDFs)"
      exports: ["extract_tokens_from_page"]
    - path: "src/pipeline/ocr_abstraction.py"
      provides: "OCR abstraction layer with Tesseract implementation, returning tokens + bbox + confidence"
      exports: ["OCREngine", "extract_tokens_with_ocr"]
  key_links:
    - from: "src/pipeline/tokenizer.py"
      to: "src/models/token.py"
      via: "Creates Token instances from pdfplumber output"
      pattern: "Token\("
    - from: "src/pipeline/ocr_abstraction.py"
      to: "src/models/token.py"
      via: "Creates Token instances from OCR output (TSV/HOCR)"
      pattern: "Token\("
    - from: "src/pipeline/tokenizer.py"
      to: "src/models/page.py"
      via: "Adds tokens to Page.tokens list"
      pattern: "page\\.tokens\\.append|page\\.tokens ="
    - from: "src/pipeline/ocr_abstraction.py"
      to: "src/models/page.py"
      via: "Requires Page with rendered_image_path for OCR"
      pattern: "rendered_image_path"
---

<objective>
Implement token extraction with spatial information from both searchable and scanned PDFs.

Purpose: Extract all text as tokens with bounding boxes (x, y, width, height) preserving spatial information. This enables layout-driven analysis in later steps. OCR abstraction layer allows switching engines without changing pipeline.
Output: Token model, tokenizer for pdfplumber path, OCR abstraction layer with Tesseract implementation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-document-normalization/01-CONTEXT.md
@.planning/research/STACK.md
@docs/02_data-model.md
@specs/invoice_pipeline_v1.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Token data model</name>
  <files>src/models/token.py</files>
  <action>
Create Token class according to docs/02_data-model.md specifications.

Token class:
- text: str (the text content)
- x: float (X-coordinate, left edge, origin at top-left)
- y: float (Y-coordinate, top edge, origin at top-left, Y increases downward)
- width: float (token width)
- height: float (token height)
- page: Page (reference to parent Page for traceability)
- font_size: Optional[float] (if available from source)
- font_name: Optional[str] (if available from source)

Coordinate system:
- Origin (0, 0) is top-left corner
- X increases rightward
- Y increases downward

Use dataclass or Pydantic. Add type hints. Ensure Token maintains page reference for full traceability back to source PDF.
  </action>
  <verify>python -m mypy src/models/token.py --python-version 3.11</verify>
  <done>Token class defined with all required fields including bbox (x, y, width, height), type hints pass mypy validation</done>
</task>

<task type="auto">
  <name>Task 2: Implement tokenizer for searchable PDFs (pdfplumber path)</name>
  <files>src/pipeline/tokenizer.py</files>
  <action>
Implement token extraction from searchable PDFs using pdfplumber.

Function to implement:
- `extract_tokens_from_page(page: Page, pdfplumber_page) -> List[Token]`: Extracts tokens from pdfplumber page object with spatial information.

For each text object from pdfplumber:
- Extract text content
- Extract bbox: x0, y0 (top-left), x1, y1 (bottom-right)
- Calculate width = x1 - x0, height = y1 - y0
- Create Token with text, x (x0), y (y0), width, height, page reference
- Extract font_size and font_name if available from pdfplumber

Preserve reading order (top-to-bottom, left-to-right). Ensure all tokens have valid bbox (non-zero width/height). Handle edge cases: empty text, overlapping tokens, font info missing.

Add tokens to Page.tokens list for traceability. Coordinate system must match Page dimensions (ensure pdfplumber coordinates align with Page.width/height).
  </action>
  <verify>python -c "from src.pipeline.reader import read_pdf; from src.pipeline.tokenizer import extract_tokens_from_page; import pdfplumber; doc = read_pdf('tests/fixtures/pdfs/sample_invoice_1.pdf'); pdf = pdfplumber.open(doc.filepath); page = doc.pages[0]; tokens = extract_tokens_from_page(page, pdf.pages[0]); assert len(tokens) > 0; assert all(t.x >= 0 and t.y >= 0 and t.width > 0 and t.height > 0 for t in tokens)"</verify>
  <done>extract_tokens_from_page extracts tokens with valid bbox from pdfplumber, tokens added to Page.tokens, reading order preserved</done>
</task>

<task type="auto">
  <name>Task 3: Implement OCR abstraction layer with Tesseract</name>
  <files>src/pipeline/ocr_abstraction.py</files>
  <action>
Implement OCR abstraction layer that allows switching OCR engines without changing pipeline.

Design:
- Abstract base class or protocol: `OCREngine` interface
- Tesseract implementation: `TesseractOCREngine` class
- Function: `extract_tokens_with_ocr(page: Page) -> List[Token]`: Returns tokens + bbox + confidence

TesseractOCREngine implementation:
- Use pytesseract wrapper
- Configure Swedish language (swe): `lang='swe'`
- Use TSV or HOCR output format to get bbox + confidence (not just raw text)
- Parse TSV/HOCR to extract:
  - text (recognized text)
  - bbox (x, y, width, height) from Tesseract coordinates
  - confidence (0.0-1.0) from Tesseract confidence scores
- Create Token objects with page reference
- Convert Tesseract coordinates to Page coordinate system (standardize to match pdfplumber coordinate system)

Abstraction design:
- OCREngine interface has method: `extract_tokens(page: Page) -> List[Token]`
- TesseractOCREngine implements OCREngine
- Design allows future implementations (PaddleOCR, EasyOCR) by implementing same interface

Error handling: If Tesseract not installed or Swedish language data missing, raise clear error with installation instructions. If OCR fails, return empty list or raise exception (caller handles).
  </action>
  <verify>python -c "from src.pipeline.ocr_abstraction import OCREngine, TesseractOCREngine; engine = TesseractOCREngine(); assert hasattr(engine, 'extract_tokens'); assert isinstance(engine, OCREngine)"</verify>
  <done>OCR abstraction layer implemented, TesseractOCREngine extracts tokens with bbox + confidence from TSV/HOCR, interface allows future engine switching</done>
</task>

<task type="auto">
  <name>Task 4: Write unit tests for token extraction</name>
  <files>tests/test_tokenizer.py</files>
  <action>
Create unit tests for token extraction from both searchable and scanned PDFs.

Tests to write:
- test_tokenizer.py:
  - Test pdfplumber token extraction (searchable PDF path)
  - Test OCR token extraction (if test corpus has scanned PDF)
  - Test token bbox validity (x, y, width, height all valid)
  - Test reading order preservation
  - Test token-page reference (traceability)

Test with sample_invoice_1.pdf. Verify:
- Tokens extracted have valid bbox
- Tokens maintain reading order
- Token.page reference is correct
- Font info extracted when available

If test corpus has scanned PDF, test OCR path. Otherwise, mock OCR for testing abstraction layer interface.

Use pytest fixtures. Ensure tests run with `pytest tests/test_tokenizer.py -v`.
  </action>
  <verify>pytest tests/test_tokenizer.py -v</verify>
  <done>All token extraction unit tests pass, coverage >80% for tokenizer and ocr_abstraction modules</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] pytest tests/test_tokenizer.py -v passes
- [ ] mypy type checking passes for all new files
- [ ] Tokens extracted with valid bbox (x, y, width, height) from pdfplumber
- [ ] OCR abstraction layer interface designed for engine switching
- [ ] Tesseract implementation returns tokens + bbox + confidence
- [ ] All tokens maintain page reference for traceability
</verification>

<success_criteria>

- All tasks completed
- Token model matches docs/02_data-model.md specification
- Tokenizer extracts tokens with spatial info from pdfplumber
- OCR abstraction layer allows switching engines
- Tesseract implementation returns tokens + bbox + confidence (not just raw text)
- Unit tests pass with >80% coverage
- No type errors or linting issues

</success_criteria>

<output>
After completion, create `.planning/phases/01-document-normalization/01-02-SUMMARY.md`
</output>
