---
phase: 14-extraction-fallback-optimization-pdfplumber-ocr-ai-vision
plan: 03
type: execute
wave: 2
depends_on: ["14-01"]
files_modified: [src/pipeline/text_quality.py]
autonomous: true

must_haves:
  truths:
    - "Deterministic text quality score [0..1] per page exists for pdf and OCR text"
    - "score_text_quality(text, tokens) and score_ocr_quality(tokens) are available"
    - "Factors include nonempty_ratio, weird_char_ratio, alpha_num_ratio, token length sanity; optional invoice keywords"
  artifacts:
    - path: "src/pipeline/text_quality.py"
      provides: "score_text_quality, score_ocr_quality"
      exports: ["score_text_quality", "score_ocr_quality"]
  key_links:
    - from: "orchestration / routing"
      to: "src/pipeline/text_quality.py"
      via: "Call score_text_quality / score_ocr_quality for thresholds (e.g. TEXT_QUALITY_THRESHOLD=0.5)"
---

<objective>
Implement text quality scoring module src/pipeline/text_quality.py. Deterministic score [0..1] per page; separate pdf_text_quality and ocr_text_quality. Used by routing to decide AI text-only vs vision. Per 14-CONTEXT §4 and 14-DISCUSS implementation task 3.
</objective>

<execution_context>
@.planning/phases/14-extraction-fallback-optimization-pdfplumber-ocr-ai-vision/14-CONTEXT.md
@.planning/phases/14-extraction-fallback-optimization-pdfplumber-ocr-ai-vision/14-DISCUSS.md
@.planning/phases/14-extraction-fallback-optimization-pdfplumber-ocr-ai-vision/14-RESEARCH.md
</execution_context>

<context>
@.planning/phases/14-extraction-fallback-optimization-pdfplumber-ocr-ai-vision/14-CONTEXT.md
@.planning/phases/14-extraction-fallback-optimization-pdfplumber-ocr-ai-vision/14-DISCUSS.md
@src/models/token.py
</context>

<tasks>

<task type="auto">
  <name>Create src/pipeline/text_quality.py</name>
  <files>src/pipeline/text_quality.py</files>
  <action>
Create module with at least:
- score_text_quality(text: str, tokens: List[Token]) -> float   # for pdfplumber-derived text
- score_ocr_quality(tokens: List[Token]) -> float   # for OCR tokens; can use token.confidence and character/token checks

Return value in [0.0, 1.0]. Implementation details (weights, formula) are at implementer's discretion per 14-CONTEXT "Claude's discretion", but factors should include: nonempty_ratio, weird_char_ratio, alpha_num_ratio, token length sanity; optional keyword hits (Total, Moms, Faktura, Bankgiro). score_ocr_quality may incorporate confidence (e.g. median or mean of token.confidence) as part of the score.
</action>
</task>

<task type="auto">
  <name>Wire into pipeline imports</name>
  <files>src/pipeline/__init__.py or call sites</files>
  <action>
Ensure text_quality can be imported from the pipeline package (or from src.pipeline.text_quality). No need to call it from orchestration in this plan — that is 14-06. This plan only adds the module and guarantees the two functions exist and return floats in [0, 1].
</action>
</task>

</tasks>

<verification>
- score_text_quality(text, tokens) and score_ocr_quality(tokens) exist and return float in [0.0, 1.0].
- Module is importable and documented (docstrings) for use by orchestration.
</verification>
