---
phase: 11-pdfplumber-ocr-compare
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [src/pipeline/ocr_abstraction.py, src/pipeline/pdf_renderer.py, src/cli/main.py, src/pipeline/invoice_boundary_detection.py, pyproject.toml]
autonomous: true

must_haves:
  truths:
    - "OCR tokens use page coordinates (points) so segment identification works"
    - "OCR extraction path produces tokens from rendered page images via Tesseract"
    - "process_invoice and process_virtual_invoice use OCR when extraction_path is ocr"
  artifacts:
    - path: "src/pipeline/ocr_abstraction.py"
      provides: "OCR token extraction with coordinate scaling"
      exports: ["extract_tokens_with_ocr", "TesseractOCREngine"]
    - path: "src/pipeline/pdf_renderer.py"
      provides: "Page render to image for OCR"
      exports: ["render_page_to_image"]
  key_links:
    - from: "src/cli/main.py"
      to: "src/pipeline/ocr_abstraction.py"
      via: "Calls extract_tokens_with_ocr when extraction_path is ocr"
      pattern: "extract_tokens_with_ocr|ocr"
    - from: "src/pipeline/ocr_abstraction.py"
      to: "src/pipeline/pdf_renderer.py"
      via: "Expects page.rendered_image_path from render_page_to_image"
      pattern: "rendered_image_path"
---

<objective>
Wire OCR extraction path: scale OCR token coordinates to page space, render pages for OCR, and use OCR in process_invoice / process_virtual_invoice when extraction_path is "ocr".

Purpose: Replace "OCR not implemented" with a working OCR path. Tokens must be in page coordinates so segment_identification (header 30%, footer 70%) works. Add pytesseract and pillow to dependencies.

Output: OCR path produces tokens → same pipeline (rows, segments, line items, footer) as pdfplumber.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/11-pdfplumber-ocr-compare/11-CONTEXT.md
@.planning/ROADMAP.md
@src/pipeline/ocr_abstraction.py
@src/pipeline/pdf_renderer.py
@src/cli/main.py
@src/pipeline/invoice_boundary_detection.py
@src/pipeline/segment_identification.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Scale OCR token coordinates to page points</name>
  <files>src/pipeline/ocr_abstraction.py</files>
  <action>
Fix OCR token coordinates so they use page space (points).

**Current:** Tesseract returns pixel coordinates. Page and segment_identification use points. Render is 300 DPI, so scale = 72/300 (points per pixel).

**Changes:**
1. In `TesseractOCREngine.extract_tokens`, after loading the image, get `img.size` (width, height) in pixels.
2. Get `page.width` and `page.height` in points (from Page, which uses pdfplumber dimensions).
3. Compute `scale_x = page.width / img_width`, `scale_y = page.height / img_height`. Use these to scale each token's x, y, width, height from pixels to points before creating the Token.
4. Create Token with scaled coordinates. Remove or resolve the "TODO: Proper coordinate transformation" comment.

**Acceptance:**
- OCR tokens have (x, y, width, height) in page points.
- Segment identification (header/footer Y thresholds) works correctly for OCR-derived tokens.
</action>
</task>

<task type="auto">
  <name>Task 2: Add OCR dependencies</name>
  <files>pyproject.toml</files>
  <action>
Add optional or required dependencies for OCR.

- Add `pytesseract` and `pillow` to `[project] dependencies` (or `[project.optional-dependencies] ocr` if we want OCR optional). Ensure version constraints (e.g. `pytesseract>=0.3.10`, `pillow>=10.0.0`).
- Document in README or phase notes: Tesseract must be installed on the system with Swedish (`swe`) language data.

**Acceptance:**
- `pip install -e .` installs pytesseract and pillow.
- Tesseract + swe is required for OCR path; detect and log clearly if missing.
</action>
</task>

<task type="auto">
  <name>Task 3: Wire OCR path in process_invoice</name>
  <files>src/cli/main.py</files>
  <action>
Implement OCR extraction in `process_invoice` when `extraction_path == "ocr"`.

**Current:** When extraction_path is "ocr", we log a warning and produce no tokens. Pdfplumber path opens PDF and uses `extract_tokens_from_page` per page.

**Changes:**
1. Create an output directory for rendered images, e.g. `output_dir / "ocr_render"` or under a temp/artifacts path. Reuse across pages.
2. For each page in the loop, when `extraction_path == "ocr"`:
   - Call `render_page_to_image(page, str(ocr_render_dir))` (from pdf_renderer). This sets `page.rendered_image_path`.
   - Call `extract_tokens_with_ocr(page)` (from ocr_abstraction). Append returned tokens to the page (or use them in the same way as pdfplumber tokens).
3. Keep the same flow: `group_tokens_to_rows(tokens)` → `identify_segments(rows, page)` → collect segments, then items. Ensure we do **not** open pdfplumber when using OCR path.
4. Handle errors: if render or OCR fails for a page, log and optionally skip that page or fail the invoice per existing error-handling policy.

**Acceptance:**
- With `extraction_path == "ocr"` (e.g. force via route_extraction_path returning "ocr" for a scanned PDF, or a temporary override for testing), process_invoice produces segments and line items from OCR.
- No pdfplumber usage when OCR path is active for token extraction.
</action>
</task>

<task type="auto">
  <name>Task 4: Wire OCR path in process_virtual_invoice and boundary detection</name>
  <files>src/cli/main.py, src/pipeline/invoice_boundary_detection.py</files>
  <action>
Implement OCR extraction in `process_virtual_invoice` and in `detect_invoice_boundaries` when `extraction_path == "ocr"`.

**process_virtual_invoice:** Same pattern as process_invoice: when "ocr", render each page in the invoice range to `ocr_render` dir, then `extract_tokens_with_ocr(page)`. Use tokens for rows → segments → line items, header, footer. Remove "OCR path not yet implemented" warning.

**invoice_boundary_detection:** The detector uses tokens per page for boundary detection. When `extraction_path == "ocr"`, use render + OCR for each page instead of pdfplumber. Ensure we have an `ocr_render` output dir (pass output_dir or artifacts path; may need to extend the function signature if it doesn't have it).

**Acceptance:**
- process_virtual_invoice and boundary detection use OCR when extraction_path is "ocr".
- No remaining "OCR path not yet implemented" for these code paths.
</action>
</task>

</tasks>
