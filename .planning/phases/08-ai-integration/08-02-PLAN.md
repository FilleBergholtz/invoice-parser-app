---
phase: 08-ai-integration
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified: [src/pipeline/footer_extractor.py, src/config.py]
autonomous: true

must_haves:
  truths:
    - "System activates AI fallback when total amount confidence < 0.95"
    - "System uses AI to extract total amount when heuristics fail"
    - "AI result validated before using"
    - "System handles AI errors gracefully (doesn't break extraction)"
  artifacts:
    - path: "src/pipeline/footer_extractor.py"
      provides: "AI fallback integration in total extraction"
      exports: []
  key_links:
    - from: "src/pipeline/footer_extractor.py"
      to: "src/ai/fallback.py"
      via: "Calls extract_total_with_ai when confidence < 0.95"
      pattern: "extract_total_with_ai"
    - from: "src/pipeline/footer_extractor.py"
      to: "src/models/invoice_header.py"
      via: "Updates InvoiceHeader with AI-extracted total if better"
      pattern: "InvoiceHeader|total_amount|total_confidence"
---

<objective>
Integrate AI fallback into footer extractor to activate when confidence < 0.95 and use AI result if validation passes.

Purpose: Add AI fallback call in extract_total_amount() after heuristic extraction. Check confidence, if < 0.95, call AI. Validate AI result and use if better than heuristic result.

Output: AI fallback integrated into footer extractor with confidence threshold check.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-ai-integration/08-CONTEXT.md
@src/ai/fallback.py
@src/pipeline/footer_extractor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add AI provider config functions</name>
  <files>src/config.py</files>
  <action>
Add configuration functions for AI provider selection.

**Functions to add:**
- `get_ai_provider() -> str`: Get AI provider name ("openai" or "claude"), default "openai"
- `get_ai_model() -> str`: Get AI model name (provider-specific), default based on provider

**Environment Variables:**
- `AI_PROVIDER`: "openai" or "claude" (default: "openai")
- `AI_MODEL`: Model name (optional, uses provider defaults if not set)
  - OpenAI default: "gpt-4-turbo-preview"
  - Claude default: "claude-3-opus-20240229"

**Implementation:**
- Check AI_PROVIDER env var, default to "openai"
- Check AI_MODEL env var, use provider default if not set
- Validate provider name (raise ValueError if invalid)

Add to config/__init__.py exports.
  </action>
  <verify>python -c "from src.config import get_ai_provider, get_ai_model; print('AI config functions imported')"</verify>
  <done>AI provider config functions added</done>
</task>

<task type="auto">
  <name>Task 2: Integrate AI fallback into footer extractor</name>
  <files>src/pipeline/footer_extractor.py</files>
  <action>
Integrate AI fallback into extract_total_amount() function.

**Update extract_total_amount():**
- After heuristic extraction and pattern matching (before calibration)
- Check if total_confidence < 0.95 and AI is enabled
- If yes, call AI fallback with footer text and line_items_sum
- If AI succeeds and validation passes:
  - Use AI result if confidence is higher than heuristic
  - Update InvoiceHeader with AI-extracted total and confidence
  - Log AI usage for monitoring

**Integration Points:**
- After Step 2 (candidate scoring) or Step 3 (pattern matching)
- Before Step 4 (calibration)
- Use footer_segment.raw_text or concatenated footer rows for AI input
- Use line_items_sum from validation for AI context

**AI Fallback Logic:**
- Only activate if get_ai_enabled() and total_confidence < 0.95
- Call extract_total_with_ai(footer_text, line_items_sum)
- If AI returns result:
  - Validate AI result (check total_amount, confidence)
  - Compare with heuristic result
  - Use AI result if confidence is higher
  - Update candidates list if AI result is better

**Error Handling:**
- Catch all AI errors gracefully
- Log warnings but continue with heuristic result
- Don't break extraction if AI fails
- Track AI usage for monitoring (<20% target)

**Logging:**
- Log when AI fallback is activated
- Log AI result and confidence
- Log if AI result is used or rejected

Update imports and ensure AI fallback is optional (doesn't break if AI not available).
  </action>
  <verify>python -c "from src.pipeline.footer_extractor import extract_total_amount; print('Footer extractor integrates AI fallback')"</verify>
  <done>AI fallback integrated into footer extractor with confidence threshold check</done>
</task>

</tasks>
